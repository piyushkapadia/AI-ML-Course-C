{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allen-p/_sent_mail/10.</td>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allen-p/_sent_mail/100.</td>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allen-p/_sent_mail/1000.</td>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allen-p/_sent_mail/1001.</td>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file                                            message\n",
       "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Enron emails dataset\n",
    "enron_emails = pd.read_csv('enron_emails.csv')\n",
    "\n",
    "# Display the first few rows to verify\n",
    "enron_emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517401 entries, 0 to 517400\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   file     517401 non-null  object\n",
      " 1   message  517401 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 7.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517401</td>\n",
       "      <td>517401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>517401</td>\n",
       "      <td>517401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>allen-p/_sent_mail/1.</td>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         file  \\\n",
       "count                  517401   \n",
       "unique                 517401   \n",
       "top     allen-p/_sent_mail/1.   \n",
       "freq                        1   \n",
       "\n",
       "                                                  message  \n",
       "count                                              517401  \n",
       "unique                                             517401  \n",
       "top     Message-ID: <18782981.1075855378110.JavaMail.e...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_emails.info()\n",
    "enron_emails.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Dev\\Tools\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load NER model\n",
    "ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-base-NER\", aggregation_strategy=\"simple\", device=0)\n",
    "\n",
    "def extract_signature(email_body):\n",
    "    # Step 1: Use NER to extract entities (name, job title)\n",
    "    ner_results = ner_pipeline(email_body)\n",
    "    \n",
    "    # Step 2: Extract PERSON and ORG entities\n",
    "    person_name = []\n",
    "    job_title = []\n",
    "    \n",
    "    for entity in ner_results:\n",
    "        if entity[\"entity_group\"] == \"PER\":\n",
    "            person_name.append(entity[\"word\"])\n",
    "        elif entity[\"entity_group\"] in [\"ORG\", \"MISC\"]:\n",
    "            job_title.append(entity[\"word\"])\n",
    "    \n",
    "    full_name = \" \".join(person_name) if person_name else \"None\"\n",
    "    job_title_text = \" \".join(job_title) if job_title else \"None\"\n",
    "    \n",
    "    # Step 3: Extract email using regex\n",
    "    email_match = re.search(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", email_body)\n",
    "    email_address = email_match.group(0) if email_match else \"None\"\n",
    "\n",
    "    # Step 4: Return dictionary output\n",
    "    # signature_text' and 'sender' columns\n",
    "    return {\n",
    "        \"signature_text\": full_name + \"|\" + job_title_text + \"|\" +email_address,\n",
    "        \"sender\": email_address,\n",
    "        \"name\": full_name,\n",
    "        \"title\": job_title_text,\n",
    "        \"email\": email_address\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dev\\Tools\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alyse.herasimchuk@enron.com', 'jsmith@austintx.com', '1.11913372.-2@multexinvestornetwork.com', 'messenger@ecm.bloomberg.com', 'bounce-news-932653@lists.autoweb.com', 'perfmgmt@enron.com', 'ina.rangel@enron.com', 'mark.whitt@enron.com', 'yahoo-delivers@yahoo-inc.com', 'subscriptions@intelligencepress.com', 'stephanie.miller@enron.com', 'christi.nicolay@enron.com', 'kim.ward@enron.com', 'ei_editor@ftenergy.com', 'billc@greenbuilder.com', 'rebecca.cantrell@enron.com', 'rob_tom@freenet.carleton.ca', 'yild@zdemail.zdlists.com', 'richard.shapiro@enron.com', 'philip.polsky@enron.com', 'webmaster@earnings.com', 'public.relations@enron.com', 'jfreeman@ssm.net', 'lisa.jacobson@enron.com', 'gthorse@keyad.com', 'tiffany.miller@enron.com', 'bobregon@bga.com', 'grensheltr@aol.com', 'tim.heizenrader@enron.com', 'owner-strawbale@crest.org', 'sarah.novosel@enron.com', 'announce@inbox.nytimes.com', 'frank.hayden@enron.com', 'phillip.allen@enron.com', 'calxa@aol.com', 'matt@fastpacket.net', 'aod@newsdata.com', 'paul.kaufman@enron.com', 'tracy.arthur@enron.com', 'market-reply@listserv.dowjones.com', 'critical.notice@enron.com'}\n"
     ]
    }
   ],
   "source": [
    "df = enron_emails.copy()\n",
    "#df_subset = df\n",
    "\n",
    "# Apply extraction to the first 10 rows\n",
    "df_subset = df.iloc[:1000].copy()  # Select first 10 rows\n",
    "df_subset[\"signature\"] = df_subset[\"message\"].apply(extract_signature)\n",
    "\n",
    "# Display the output of emails only\n",
    "email_values = [signature.get(\"email\") for signature in df_subset[\"signature\"]]\n",
    "# Create a DataFrame with signature_text and sender columns\n",
    "signature_df = pd.DataFrame(df_subset[\"signature\"].tolist(), columns=[\"signature_text\", \"sender\"])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "signature_df.to_csv(\"signature.csv\", index=False)\n",
    "#print(email_values)\n",
    "unique_emails = set(email_values)\n",
    "print(unique_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"signature_data.csv\")  # Should contain 'signature_text' and 'sender' columns\n",
    "\n",
    "# Encode sender labels numerically\n",
    "df['label'] = df['sender'].astype('category').cat.codes\n",
    "\n",
    "# Split dataset\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"signature_text\"], truncation=True, padding=True)\n",
    "\n",
    "print(df.head)\n",
    "#t1 = train_dataset.map(tokenize_function, batched=True)\n",
    "#t1 =tokenize_function(df[0][\"signature_text\"])\n",
    "#print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT Predicted Sender Class:\n",
      "[{'label': 'O', 'score': 0.2072329819202423}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Pre-trained model pipeline (for demo purpose, general model)\n",
    "classifier = pipeline(\"text-classification\", model=\"dslim/bert-base-NER\")\n",
    "\n",
    "email_signature = \"John Doe, Senior Analyst, john.doe@example.com\"\n",
    "\n",
    "result = classifier(email_signature)\n",
    "print(\"BERT Predicted Sender Class:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e0e8445f014804ae37b0eb1914dc4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744da48baa5b4c34b26ffb1e18d585b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\Dev\\Tools\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631285eecb294fb3a3e2e5f217165e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55b729eb77a4fb8b2f9e100ebafa6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3351209759712219, 'eval_runtime': 0.7064, 'eval_samples_per_second': 283.122, 'eval_steps_per_second': 18.403, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67eda83e928c4ae7a37ca7856e415188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19635699689388275, 'eval_runtime': 0.6997, 'eval_samples_per_second': 285.837, 'eval_steps_per_second': 18.579, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc02f2cac5b94041903f1fc9f87eda7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19058085978031158, 'eval_runtime': 0.6735, 'eval_samples_per_second': 296.954, 'eval_steps_per_second': 19.302, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0052f6058c614d5eba8d17fde79b0251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1839957982301712, 'eval_runtime': 0.6723, 'eval_samples_per_second': 297.494, 'eval_steps_per_second': 19.337, 'epoch': 4.0}\n",
      "{'train_runtime': 42.1627, 'train_samples_per_second': 75.896, 'train_steps_per_second': 4.744, 'train_loss': 0.5025893402099609, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106164add3754d988580a4eab47e53a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1839957982301712,\n",
       " 'eval_runtime': 0.673,\n",
       " 'eval_samples_per_second': 297.193,\n",
       " 'eval_steps_per_second': 19.318,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"signature_text\"], truncation=True, padding=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Load BERT model\n",
    "# \"dslim/bert-base-NER\"\n",
    "# \"bert-base-uncased\"\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=df['label'].nunique())\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_sender_detection_new\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for './bert_sender_detection_new'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './bert_sender_detection_new' is the correct path to a directory containing all relevant files for a BertTokenizer tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m model_path = \u001b[33m\"\u001b[39m\u001b[33m./bert_sender_detection_new\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Folder where model was saved\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#model_path = r\"D:\\Dev\\GitHub\\AI-ML-Course\\Projects\\External\\Signature\\bert_sender_detection\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m tokenizer = \u001b[43mBertTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m model = BertForSequenceClassification.from_pretrained(model_path)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Label mapping (you can save/load it too)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Dev\\Tools\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2192\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[39m\n\u001b[32m   2189\u001b[39m \u001b[38;5;66;03m# If one passes a GGUF file path to `gguf_file` there is no need for this check as the tokenizer will be\u001b[39;00m\n\u001b[32m   2190\u001b[39m \u001b[38;5;66;03m# loaded directly from the GGUF file.\u001b[39;00m\n\u001b[32m   2191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files.values()) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gguf_file:\n\u001b[32m-> \u001b[39m\u001b[32m2192\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m   2193\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt load tokenizer for \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. If you were trying to load it from \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2194\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/models\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, make sure you don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt have a local directory with the same name. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2195\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOtherwise, make sure \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is the correct path to a directory \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2196\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tokenizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2197\u001b[39m     )\n\u001b[32m   2199\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files.items():\n\u001b[32m   2200\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[31mOSError\u001b[39m: Can't load tokenizer for './bert_sender_detection_new'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure './bert_sender_detection_new' is the correct path to a directory containing all relevant files for a BertTokenizer tokenizer."
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load trained model & tokenizer\n",
    "model_path = \"./bert_sender_detection_new\"  # Folder where model was saved\n",
    "#model_path = r\"D:\\Dev\\GitHub\\AI-ML-Course\\Projects\\External\\Signature\\bert_sender_detection\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Label mapping (you can save/load it too)\n",
    "label_to_sender = {0: \"John Doe\", 1: \"Jane Smith\"}  # Example mapping\n",
    "\n",
    "def predict_sender(signature_text):\n",
    "    inputs = tokenizer(signature_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    predicted_label = torch.argmax(probs, dim=1).item()\n",
    "    confidence = probs[0][predicted_label].item()\n",
    "    return label_to_sender[predicted_label], confidence\n",
    "\n",
    "# Example usage\n",
    "signature = \"John Doe, Senior Analyst, john@example.com\"\n",
    "sender, confidence = predict_sender(signature)\n",
    "print(f\"Predicted Sender: {sender}, Confidence: {confidence:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn, xgboost\n",
    "print(f\"scikit-learn version: {sklearn.__version__}\") \n",
    "print(f\"XGBoost version: {xgboost.__version__}\") \n",
    "# for xgboost error with sklearn use these versions\n",
    "scikit-learn version: 1.5.2\n",
    "XGBoost version: 2.1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
